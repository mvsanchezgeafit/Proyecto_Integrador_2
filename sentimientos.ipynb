{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import json\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, roc_curve, auc\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "\n",
    "from io import StringIO\n",
    "from io import BytesIO\n",
    "\n",
    "import psycopg2\n",
    "import re\n",
    "from urllib.request import urlopen\n",
    "import time\n",
    "from urllib.parse import quote\n",
    "import urllib.parse\n",
    "import sys\n",
    "import yaml\n",
    "from transformers import pipeline\n",
    "\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.yaml', \"r\", encoding='utf8') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "\n",
    "stop_words = set(stopwords.words('spanish'))\n",
    "\n",
    "\n",
    "def consulta_comentarios(config):\n",
    "        print(\"Cargando comentarios\")\n",
    "\n",
    "        sql_coment = f\"\"\"\n",
    "        SELECT * FROM (\n",
    "        SELECT  com.rowid_publicacion_meta, comentario, fecha_comentario,  EXTRACT(year from fecha_publicacion) as \"aÃ±o\", comentario_limpio, metricool.url_imagen\n",
    "\t    FROM public.tr_comentarios com \n",
    "\t        INNER JOIN public.tr_publicaciones_meta meta on meta.rowid_publicacion_meta = com.rowid_publicacion_meta\n",
    "\t        INNER JOIN public.tr_publicaciones metricool on metricool.url = meta.url ) as TAB\n",
    "        WHERE \"aÃ±o\" in ('2021','2022','2023','2024') \n",
    "\n",
    "            \"\"\"\n",
    "        with psycopg2.connect(**config['conexion_bodega']['tr_staging_hermes']['connection_string']) as conn:\n",
    "            with conn.cursor() as cursor:\n",
    "                cursor.execute(sql_coment)\n",
    "                columnas = [column[0] for column in cursor.description]\n",
    "                data = cursor.fetchall()\n",
    "        \n",
    "        comentarios =  pd.DataFrame(data, columns=columnas)\n",
    "        return comentarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando comentarios\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rowid_publicacion_meta</th>\n",
       "      <th>comentario</th>\n",
       "      <th>fecha_comentario</th>\n",
       "      <th>aÃ±o</th>\n",
       "      <th>comentario_limpio</th>\n",
       "      <th>url_imagen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17968369664400424</td>\n",
       "      <td>precio porfa</td>\n",
       "      <td>2023-09-03 17:40:37</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>precio porfa</td>\n",
       "      <td>https://scontent-lhr8-2.cdninstagram.com/v/t51...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17966597753258208</td>\n",
       "      <td>Las 3 ultimas pagas y la primera ya casi. Son ...</td>\n",
       "      <td>2023-03-10 17:09:15</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>ultimas pagas primera casi excelentes herramie...</td>\n",
       "      <td>https://scontent-lhr6-2.cdninstagram.com/v/t39...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17972428982047533</td>\n",
       "      <td>ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚</td>\n",
       "      <td>2023-04-07 11:31:41</td>\n",
       "      <td>2023.0</td>\n",
       "      <td></td>\n",
       "      <td>https://scontent-lhr6-1.cdninstagram.com/v/t39...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17972428982047533</td>\n",
       "      <td>Jajajajajajajaaj</td>\n",
       "      <td>2023-04-07 14:36:21</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>jajajajajajajaaj</td>\n",
       "      <td>https://scontent-lhr6-1.cdninstagram.com/v/t39...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17972428982047533</td>\n",
       "      <td>ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚</td>\n",
       "      <td>2023-04-07 11:17:50</td>\n",
       "      <td>2023.0</td>\n",
       "      <td></td>\n",
       "      <td>https://scontent-lhr6-1.cdninstagram.com/v/t39...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  rowid_publicacion_meta                                         comentario  \\\n",
       "0      17968369664400424                                       precio porfa   \n",
       "1      17966597753258208  Las 3 ultimas pagas y la primera ya casi. Son ...   \n",
       "2      17972428982047533                                               ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚   \n",
       "3      17972428982047533                                   Jajajajajajajaaj   \n",
       "4      17972428982047533                                              ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚   \n",
       "\n",
       "     fecha_comentario     aÃ±o  \\\n",
       "0 2023-09-03 17:40:37  2023.0   \n",
       "1 2023-03-10 17:09:15  2023.0   \n",
       "2 2023-04-07 11:31:41  2023.0   \n",
       "3 2023-04-07 14:36:21  2023.0   \n",
       "4 2023-04-07 11:17:50  2023.0   \n",
       "\n",
       "                                   comentario_limpio  \\\n",
       "0                                       precio porfa   \n",
       "1  ultimas pagas primera casi excelentes herramie...   \n",
       "2                                                      \n",
       "3                                   jajajajajajajaaj   \n",
       "4                                                      \n",
       "\n",
       "                                          url_imagen  \n",
       "0  https://scontent-lhr8-2.cdninstagram.com/v/t51...  \n",
       "1  https://scontent-lhr6-2.cdninstagram.com/v/t39...  \n",
       "2  https://scontent-lhr6-1.cdninstagram.com/v/t39...  \n",
       "3  https://scontent-lhr6-1.cdninstagram.com/v/t39...  \n",
       "4  https://scontent-lhr6-1.cdninstagram.com/v/t39...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comentarios = consulta_comentarios(config)\n",
    "comentarios.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisis de sentimientos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Etiquetado automatico - ROBERTUITO:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debido a que no se tienen etiquets manuales de los comentarios, se genera un etiquetado automatico por medio del modelo preentrenado **Robertuito**, este modelo ya tiene finen-tunning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = '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'\n",
    "sentiment_pipeline = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"pysentimiento/robertuito-sentiment-analysis\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (146 > 128). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "def predecir_sentimiento(texto):\n",
    "    try:\n",
    "        resultado = sentiment_pipeline(texto)[0]\n",
    "        return resultado['label'], resultado['score']\n",
    "    except:\n",
    "        return \"ERROR\", 0.0\n",
    "\n",
    "comentarios[['emocion', 'probabilidad']] = comentarios['comentario'].apply(lambda x: pd.Series(predecir_sentimiento(str(x))))\n",
    "\n",
    "comentarios.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "labeling filtrado por confianza:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CANTIDAD</th>\n",
       "      <th>PORCENTAJE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emocion</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NEG</th>\n",
       "      <td>4592</td>\n",
       "      <td>48.520710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POS</th>\n",
       "      <td>2585</td>\n",
       "      <td>27.314032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NEU</th>\n",
       "      <td>2287</td>\n",
       "      <td>24.165258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         CANTIDAD  PORCENTAJE\n",
       "emocion                      \n",
       "NEG          4592   48.520710\n",
       "POS          2585   27.314032\n",
       "NEU          2287   24.165258"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comentarios_filt = comentarios[comentarios[\"probabilidad\"] > 0.9]\n",
    "conteo_label = comentarios_filt['emocion'].value_counts().to_frame(name='CANTIDAD')\n",
    "conteo_label['PORCENTAJE'] = comentarios_filt['emocion'].value_counts(normalize=True) * 100\n",
    "conteo_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Entrenamiento y evaluaciÃ³n del modelo - BETO:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hot-Enconder para la columna con etiquetado automatico, uso de Datasets de transformers para utilizar el trainer de huggin face, separaciÃ³n del dataset en entrenamiento y valiaciÃ³n:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lriverosq\\AppData\\Local\\Temp\\ipykernel_29496\\3557601455.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  comentarios_filt['label'] = enconder.fit_transform(comentarios_filt['emocion'])\n"
     ]
    }
   ],
   "source": [
    "enconder = LabelEncoder()\n",
    "comentarios_filt['label'] = enconder.fit_transform(comentarios_filt['emocion'])\n",
    "train, val = train_test_split(comentarios_filt, test_size=0.2, stratify=comentarios_filt[\"label\"], random_state=42)\n",
    "\n",
    "ds_train = Dataset.from_pandas(train[[\"comentario\", \"label\"]])\n",
    "ds_val   = Dataset.from_pandas(val[[\"comentario\", \"label\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizar con transformers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1820ea8e3a140678599b7fe9ad165dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7571 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "522c8a7d8ea34a118f911ef2ecd82d36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1893 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"pysentimiento/robertuito-sentiment-analysis\")\n",
    "    \n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"comentario\"], padding='max_length', truncation=True, max_length=128)\n",
    "    \n",
    "ds_train = ds_train.map(tokenize, batched=True)\n",
    "ds_val   = ds_val.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lriverosq\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\training_args.py:1559: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\lriverosq\\AppData\\Local\\Temp\\ipykernel_29496\\819362799.py:26: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db6d56ef49c640559b78fe8075548da0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2841 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0108, 'grad_norm': 0.0025167951826006174, 'learning_rate': 1.6480112636395638e-05, 'epoch': 0.53}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05159d8378bf4bc3afb8e754b548bcfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/237 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.611218562582508e-05, 'eval_accuracy': 1.0, 'eval_f1': 1.0, 'eval_runtime': 112.4106, 'eval_samples_per_second': 16.84, 'eval_steps_per_second': 2.108, 'epoch': 1.0}\n",
      "{'loss': 0.0065, 'grad_norm': 0.024138815701007843, 'learning_rate': 1.2960225272791272e-05, 'epoch': 1.06}\n",
      "{'loss': 0.0024, 'grad_norm': 0.0008155028917826712, 'learning_rate': 9.440337909186907e-06, 'epoch': 1.58}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7070db00d1804fbda14d9b09065f9eb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/237 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.5952129615470767e-05, 'eval_accuracy': 1.0, 'eval_f1': 1.0, 'eval_runtime': 121.7688, 'eval_samples_per_second': 15.546, 'eval_steps_per_second': 1.946, 'epoch': 2.0}\n",
      "{'loss': 0.0003, 'grad_norm': 0.00045504531590268016, 'learning_rate': 5.920450545582543e-06, 'epoch': 2.11}\n",
      "{'loss': 0.0008, 'grad_norm': 0.00037310918560251594, 'learning_rate': 2.400563181978177e-06, 'epoch': 2.64}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf178cd4e919468c83348546a665b085",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/237 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1855988304887433e-05, 'eval_accuracy': 1.0, 'eval_f1': 1.0, 'eval_runtime': 119.148, 'eval_samples_per_second': 15.888, 'eval_steps_per_second': 1.989, 'epoch': 3.0}\n",
      "{'train_runtime': 10312.3629, 'train_samples_per_second': 2.203, 'train_steps_per_second': 0.275, 'train_loss': 0.0036692831633151606, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2841, training_loss=0.0036692831633151606, metrics={'train_runtime': 10312.3629, 'train_samples_per_second': 2.203, 'train_steps_per_second': 0.275, 'total_flos': 1494023764214016.0, 'train_loss': 0.0036692831633151606, 'epoch': 3.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"pysentimiento/robertuito-sentiment-analysis\", \n",
    "    num_labels=3\n",
    ")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1\": f1_score(labels, preds, average='weighted')\n",
    "    }\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"./robertuito_finetuned\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    learning_rate=2e-5,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=ds_train,\n",
    "    eval_dataset=ds_val,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('robertuito_finetuned\\\\tokenizer_config.json',\n",
       " 'robertuito_finetuned\\\\special_tokens_map.json',\n",
       " 'robertuito_finetuned\\\\tokenizer.json')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"robertuito_finetuned\")\n",
    "tokenizer.save_pretrained(\"robertuito_finetuned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluacion del modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"robertuito_finetuned\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"robertuito_finetuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd303760db9a48b896573a09d3828595",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/237 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 3.611218562582508e-05,\n",
       " 'eval_accuracy': 1.0,\n",
       " 'eval_f1': 1.0,\n",
       " 'eval_runtime': 113.8236,\n",
       " 'eval_samples_per_second': 16.631,\n",
       " 'eval_steps_per_second': 2.082,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = trainer.evaluate()\n",
    "metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
